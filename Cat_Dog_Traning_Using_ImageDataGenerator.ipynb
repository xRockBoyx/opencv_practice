{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065ca3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m執行具有 'Python 3.7.13 ('python3.7')' 的儲存格需要 ipykernel 套件。\n",
      "\u001b[1;31m執行下列命令以將 'ipykernel' 安裝到 Python 環境中。\n",
      "\u001b[1;31m命令: 'conda install -n python3.7 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import cv2, tensorflow, os, shap\n",
    "import numpy as np\n",
    "from tqdm                    import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3984814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取狗勾ㄉ照片\n",
    "for i in range(1, 16, 1):\n",
    "    img = cv2.imread('/Users/huangweikai/Desktop/PROJECTS/opencv_practice/archive/training_set/dogs/dog.'+str(i)+'.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8092b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取貓貓ㄉ照片\n",
    "for i in range(1, 16, 1):\n",
    "    img = cv2.imread('/Users/huangweikai/Desktop/PROJECTS/opencv_practice/archive/training_set/cats/cat.'+str(i)+'.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c052bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part we train our model without ImageDataGenerator(不做資料擴增的意思)\n",
    "class_names = ['cats','dogs']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "nb_classes = len(class_names)\n",
    "IMAGE_SIZE = (64, 64)\n",
    "\n",
    "class_names_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b3e9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    datasets = ['archive/training_set', 'archive/test_set']#資料夾\n",
    "    output = []\n",
    "    \n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "        \n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            if folder == \".DS_Store\":\n",
    "                continue\n",
    "            label = class_names_label[folder]\n",
    "            \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "                \n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "                if file == \"desktop.ini\":\n",
    "                    break\n",
    "                if file == \".DS_Store\":\n",
    "                    continue\n",
    "                # Open and resize the img\n",
    "                # print(img_path)\n",
    "                image = cv2.imread(img_path)\n",
    "                # print(image.shape)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                #cv讀照片，顏色莫認為BGR，需轉為RGB，錯誤表示黑白或已轉\n",
    "                image = cv2.resize(image, IMAGE_SIZE) \n",
    "                \n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')   \n",
    "        \n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83349180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading archive/training_set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4006/4006 [00:12<00:00, 317.46it/s]\n",
      "100%|██████████| 4001/4001 [00:10<00:00, 376.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading archive/test_set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1013/1013 [00:02<00:00, 366.91it/s]\n",
      "100%|██████████| 1012/1012 [00:02<00:00, 409.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[245. 215. 224.]\n",
      "   [237. 202. 204.]\n",
      "   [239. 198. 196.]\n",
      "   ...\n",
      "   [152. 118. 103.]\n",
      "   [108.  82.  74.]\n",
      "   [ 98.  77.  72.]]\n",
      "\n",
      "  [[230. 195. 198.]\n",
      "   [218. 173. 176.]\n",
      "   [202. 153. 156.]\n",
      "   ...\n",
      "   [115.  86.  78.]\n",
      "   [102.  83.  86.]\n",
      "   [100.  85.  78.]]\n",
      "\n",
      "  [[203. 147. 148.]\n",
      "   [176. 127. 130.]\n",
      "   [100.  67.  65.]\n",
      "   ...\n",
      "   [106.  83.  78.]\n",
      "   [ 97.  81.  79.]\n",
      "   [107.  85.  80.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[137.  47. 134.]\n",
      "   [143.  53. 140.]\n",
      "   [133.  43. 130.]\n",
      "   ...\n",
      "   [164. 148. 149.]\n",
      "   [157. 141. 148.]\n",
      "   [151. 134. 140.]]\n",
      "\n",
      "  [[137.  47. 134.]\n",
      "   [135.  46. 132.]\n",
      "   [137.  47. 134.]\n",
      "   ...\n",
      "   [132. 116. 118.]\n",
      "   [141. 125. 133.]\n",
      "   [143. 126. 132.]]\n",
      "\n",
      "  [[138.  50. 137.]\n",
      "   [130.  49. 133.]\n",
      "   [131.  38. 127.]\n",
      "   ...\n",
      "   [143. 127. 128.]\n",
      "   [144. 129. 129.]\n",
      "   [153. 137. 140.]]]\n",
      "\n",
      "\n",
      " [[[148. 142. 180.]\n",
      "   [150. 144. 182.]\n",
      "   [152. 146. 184.]\n",
      "   ...\n",
      "   [114.  98.  99.]\n",
      "   [113.  97.  98.]\n",
      "   [110.  94.  95.]]\n",
      "\n",
      "  [[148. 142. 180.]\n",
      "   [153. 147. 185.]\n",
      "   [155. 149. 187.]\n",
      "   ...\n",
      "   [115.  99. 100.]\n",
      "   [114.  98.  99.]\n",
      "   [110.  94.  96.]]\n",
      "\n",
      "  [[154. 148. 186.]\n",
      "   [155. 149. 187.]\n",
      "   [158. 152. 190.]\n",
      "   ...\n",
      "   [115.  99. 100.]\n",
      "   [114.  98.  99.]\n",
      "   [113.  97.  98.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[111. 110. 128.]\n",
      "   [110. 109. 127.]\n",
      "   [115. 113. 134.]\n",
      "   ...\n",
      "   [109. 107. 121.]\n",
      "   [103. 101. 114.]\n",
      "   [102. 100. 112.]]\n",
      "\n",
      "  [[108. 107. 125.]\n",
      "   [109. 108. 126.]\n",
      "   [114. 112. 133.]\n",
      "   ...\n",
      "   [104. 102. 116.]\n",
      "   [102. 100. 113.]\n",
      "   [104. 102. 113.]]\n",
      "\n",
      "  [[106. 108. 124.]\n",
      "   [109. 110. 131.]\n",
      "   [116. 118. 133.]\n",
      "   ...\n",
      "   [102. 100. 111.]\n",
      "   [107. 106. 114.]\n",
      "   [ 99.  98. 106.]]]\n",
      "\n",
      "\n",
      " [[[ 97.  59.  48.]\n",
      "   [ 81.  59.  46.]\n",
      "   [ 56.  42.  40.]\n",
      "   ...\n",
      "   [ 59.  80.  81.]\n",
      "   [ 68.  77.  82.]\n",
      "   [ 67.  76.  81.]]\n",
      "\n",
      "  [[105.  66.  49.]\n",
      "   [ 98.  62.  48.]\n",
      "   [ 74.  52.  41.]\n",
      "   ...\n",
      "   [ 62.  77.  80.]\n",
      "   [ 65.  79.  82.]\n",
      "   [ 64.  78.  81.]]\n",
      "\n",
      "  [[110.  72.  53.]\n",
      "   [110.  72.  53.]\n",
      "   [ 93.  60.  45.]\n",
      "   ...\n",
      "   [ 67.  76.  81.]\n",
      "   [ 62.  75.  84.]\n",
      "   [ 63.  76.  85.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[155. 148. 140.]\n",
      "   [144. 135. 128.]\n",
      "   [156. 145. 139.]\n",
      "   ...\n",
      "   [183. 175. 173.]\n",
      "   [179. 171. 169.]\n",
      "   [165. 157. 155.]]\n",
      "\n",
      "  [[144. 137. 129.]\n",
      "   [145. 138. 130.]\n",
      "   [154. 154. 144.]\n",
      "   ...\n",
      "   [178. 170. 167.]\n",
      "   [174. 166. 164.]\n",
      "   [175. 167. 165.]]\n",
      "\n",
      "  [[142. 134. 127.]\n",
      "   [165. 155. 147.]\n",
      "   [170. 160. 153.]\n",
      "   ...\n",
      "   [186. 174. 174.]\n",
      "   [182. 172. 171.]\n",
      "   [172. 166. 163.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[222. 217. 207.]\n",
      "   [219. 219. 176.]\n",
      "   [216. 197. 148.]\n",
      "   ...\n",
      "   [236. 233. 216.]\n",
      "   [239. 236. 220.]\n",
      "   [240. 238. 214.]]\n",
      "\n",
      "  [[218. 213. 204.]\n",
      "   [219. 219. 186.]\n",
      "   [212. 197. 157.]\n",
      "   ...\n",
      "   [236. 220. 177.]\n",
      "   [241. 232. 205.]\n",
      "   [237. 233. 222.]]\n",
      "\n",
      "  [[209. 201. 194.]\n",
      "   [223. 223. 205.]\n",
      "   [220. 210. 180.]\n",
      "   ...\n",
      "   [227. 202. 133.]\n",
      "   [229. 214. 157.]\n",
      "   [237. 234. 210.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[223. 210. 176.]\n",
      "   [213. 194. 126.]\n",
      "   [120. 112.  95.]\n",
      "   ...\n",
      "   [ 17.  17.  10.]\n",
      "   [ 25.  24.  19.]\n",
      "   [ 21.  21.  13.]]\n",
      "\n",
      "  [[210. 200. 149.]\n",
      "   [160. 137.  93.]\n",
      "   [ 36.  27.  18.]\n",
      "   ...\n",
      "   [ 13.  13.   5.]\n",
      "   [ 15.  14.   9.]\n",
      "   [ 29.  29.  21.]]\n",
      "\n",
      "  [[191. 186. 129.]\n",
      "   [ 51.  34.  25.]\n",
      "   [108.  98.  93.]\n",
      "   ...\n",
      "   [ 11.  10.   3.]\n",
      "   [ 20.  15.  11.]\n",
      "   [ 19.  14.   8.]]]\n",
      "\n",
      "\n",
      " [[[ 17.  18.  12.]\n",
      "   [ 16.  17.  11.]\n",
      "   [ 17.  16.  11.]\n",
      "   ...\n",
      "   [  8.   9.   4.]\n",
      "   [  8.   9.   4.]\n",
      "   [  8.   9.   4.]]\n",
      "\n",
      "  [[ 19.  16.   7.]\n",
      "   [ 19.  16.   7.]\n",
      "   [ 15.  15.   5.]\n",
      "   ...\n",
      "   [  8.   9.   4.]\n",
      "   [  8.   9.   4.]\n",
      "   [  7.   8.   3.]]\n",
      "\n",
      "  [[ 22.  18.   6.]\n",
      "   [ 22.  18.   6.]\n",
      "   [ 18.  19.   5.]\n",
      "   ...\n",
      "   [  8.   9.   4.]\n",
      "   [  8.   9.   4.]\n",
      "   [  9.  10.   5.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[146. 134.  94.]\n",
      "   [145. 133.  93.]\n",
      "   [140. 134.  88.]\n",
      "   ...\n",
      "   [ 41.  36.  17.]\n",
      "   [ 31.  32.  16.]\n",
      "   [ 41.  40.  24.]]\n",
      "\n",
      "  [[143. 131.  91.]\n",
      "   [142. 130.  90.]\n",
      "   [143. 136.  90.]\n",
      "   ...\n",
      "   [ 60.  56.  44.]\n",
      "   [ 65.  59.  34.]\n",
      "   [ 79.  68.  40.]]\n",
      "\n",
      "  [[140. 127.  87.]\n",
      "   [139. 127.  87.]\n",
      "   [142. 130.  90.]\n",
      "   ...\n",
      "   [ 72.  76.  41.]\n",
      "   [ 76.  73.  43.]\n",
      "   [ 73.  70.  39.]]]\n",
      "\n",
      "\n",
      " [[[123. 136. 137.]\n",
      "   [131. 145. 146.]\n",
      "   [129. 140. 142.]\n",
      "   ...\n",
      "   [ 42.  50.  53.]\n",
      "   [ 32.  37.  41.]\n",
      "   [ 29.  34.  38.]]\n",
      "\n",
      "  [[119. 133. 134.]\n",
      "   [124. 138. 139.]\n",
      "   [127. 138. 140.]\n",
      "   ...\n",
      "   [ 42.  52.  54.]\n",
      "   [ 29.  39.  41.]\n",
      "   [ 26.  36.  38.]]\n",
      "\n",
      "  [[118. 132. 133.]\n",
      "   [122. 136. 137.]\n",
      "   [128. 139. 141.]\n",
      "   ...\n",
      "   [ 33.  44.  46.]\n",
      "   [ 31.  42.  44.]\n",
      "   [ 34.  45.  47.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  2.   4.   3.]\n",
      "   [  1.   2.   1.]\n",
      "   [  1.   1.   3.]\n",
      "   ...\n",
      "   [  2.   2.   2.]\n",
      "   [  3.   3.   3.]\n",
      "   [  2.   2.   2.]]\n",
      "\n",
      "  [[  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   ...\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]]\n",
      "\n",
      "  [[  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   ...\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]]]]\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7e227fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0 \n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65509eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32 , 3, 3,  input_shape = (64, 64, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size  = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf48c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c17ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:36:46.835452: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# The function ImageDataGenerator augments your image by iterating through image as your CNN is getting ready to process that image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   horizontal_flip=True,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, \n",
    "                                   validation_split = 0.2)\n",
    "\n",
    "train_set = image_datagen.flow_from_directory(  'Images/all_set/',\n",
    "                                                 shuffle = True,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size  = 16,\n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode  = 'categorical'\n",
    "                                                 )\n",
    "test_set = image_datagen.flow_from_directory('Images/all_set/',\n",
    "                                             shuffle = True,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size  = 16,\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode  = 'categorical'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "151d6dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fa777e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 37s 146ms/step - loss: 0.5868 - accuracy: 0.6916 - val_loss: 0.5903 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd16e533310>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(  train_set,\n",
    "            steps_per_epoch = len(train_set),\n",
    "            epochs = 1,\n",
    "            validation_data = test_set,\n",
    "            validation_steps = len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23357fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 3s 10ms/step - loss: 0.6456 - accuracy: 0.5003 - val_loss: 0.6417 - val_accuracy: 0.5002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd16ccb7b50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels,\n",
    "            validation_data = (test_images,test_labels),\n",
    "            batch_size  = 32,\n",
    "            epochs = 1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc59397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cat_dog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a50c7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "576c5252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "(1, 64, 64, 3)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img('/Users/huangweikai/Desktop/PROJECTS/opencv_practice/archive/test_set/cats/cat.4004.jpg',target_size=(64,64))\n",
    "x = image.img_to_array(img)\n",
    "print(x.shape)\n",
    "x = np.expand_dims(x,axis = 0)\n",
    "\n",
    "img_data = preprocess_input(x)\n",
    "print(img_data.shape)\n",
    "classes = model.predict(img_data)\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3986e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('python3.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "307e166ebd299c6401415583392b523d927eea5f6646679dee6dd8354ebfebaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
